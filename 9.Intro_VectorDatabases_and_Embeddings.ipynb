{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9a283b99-3516-4251-840f-2c3c8eb7bca8",
   "metadata": {},
   "source": [
    "**Embeddings** are the core of building LLM applications. \n",
    "\n",
    "Text embeddings are numeric representations of text, used in NLP(natural language processing) and ML(machine learning) tasks. Text embeddings can be used to measure the relatedness and similarity between two pieces of text. Relatedness measures how closely two pieces of text are related in meaning.\n",
    "\n",
    "The distance between two embeddings or two vectors measures their relatedness which translates to the relatedness between the text concepts they represent. Similar embeddings or vectors represent similar concepts. Text concepts are words and phrases. Similar embeddings or vectors represent similar concepts.\n",
    "\n",
    "**There are two common approaches to measure relatedness and similarity between text embeddings.**\n",
    "**1)Cosine similarity and\n",
    "  2)Euclidean distance**\n",
    "\n",
    "  #### Embeddings Applications:\n",
    "  ##### 1) Text Classification:\n",
    "  Assigning a label to a piece of text.\n",
    "\n",
    "  ##### 2) Text Clustering:\n",
    "  Grouping together pieces of text that are similar in meaning.\n",
    "\n",
    "  ##### 3) Question-Answering: \n",
    "  Answering a question posed in natural language.\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b13c4cad-8892-4be2-a105-4c7a9fde0c14",
   "metadata": {},
   "source": [
    "## Vector Databases"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c792a9a-9cd0-4fb6-9992-fad1fa87ea3e",
   "metadata": {},
   "source": [
    "One of the biggest challenges of AI applications is efficient data processing. AI applications such as LLMs, Generative AI, and semantic search require a large amount of data to train and operate. Efficient data processing is essential for making AI applications successful.\n",
    "\n",
    "Many of the latest AI applications(ex. chatbots, question-answering systems, and machine translation) rely on vector embeddings.**Vector Embeddings means converting text to numbers that carry within themselves semantic information.** Vector Embeddings are a way to represent text as a set of numbers in a high dimensional space, and the numbers represent the meaning of the words in the text.\n",
    "\n",
    "We need a specialized database or data store specifically designed to manage large quantities of data in a numeric representation. There are many vector databases available, both free and commercial. **Examples: Pinecone, Chroma, Milvus, qdrant.**\n",
    "\n",
    "Pinecone is a vector database designed for storing and quering high dimensional vectors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e0abe34-6684-44af-9279-e6be16cf9d96",
   "metadata": {},
   "source": [
    "**Vector Databases are a new type of database, designed to store and query unstructured data.**\n",
    "\n",
    "**Unstructured data is data that does not have a fixed schema, such as text, images, and audio.**\n",
    "\n",
    "Just like the \"select\" statement in the SQL, in Vector databases we apply a similarity metric to find a vector that is the most similar to our query. Vector databases use a combination of different optimized algorithms that all participate in **Approximate Nearest Neighbor**(ANN) search.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "037f34d7-5970-4dea-a60a-c6ad3afdfa24",
   "metadata": {},
   "source": [
    "## How does vector database work?\n",
    "Three steps:\n",
    "\n",
    "**1)Embedding:-** Create vector embeddings for the content we want to index. This is done by using an embedding model such as Openai's \"text-embedding-ada-002\" or \"text-embedding-3-small\"\n",
    "\n",
    "**2)Indexing:-** Insert the vector embeddings into the vector database. This is done by associating each vector embedding with a reference to the original content used to create it.\n",
    "\n",
    "**3)Querying:-** Query the vector database for similar content. This is done by using the same embedding model used to create the vector embeddings. \n",
    "\n",
    "The **embedding model** is used to create a vector embedding for the query, and this vector embedding is then used to query the database for similar vector embeddings. The similar vector embeddings are then associated with the original content that was used to create them."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
