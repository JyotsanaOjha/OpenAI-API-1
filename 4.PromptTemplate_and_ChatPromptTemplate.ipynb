{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1c03e53a-a5da-4a60-a154-695e0c7f872f",
   "metadata": {},
   "source": [
    "A **prompt** refers to the input to the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19d9d00d-bdf0-4b6c-a043-6faeff8af553",
   "metadata": {},
   "source": [
    "**Prompt templates** are a way to create dynamic prompts for LLMs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7b0ab00-a171-46d9-a48c-6a4a3d460128",
   "metadata": {},
   "source": [
    "A **prompt template** takes a piece of text and injects a user's input into that piece of text."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90ee7c92-6cad-4064-89ca-3d1d1a7a8838",
   "metadata": {},
   "source": [
    "In LangChain there are **PromptTemplates** and **ChatPromptTemplates**.\n",
    "**PromptTemplates** are used for tasks that involve generating text, such as answering questions or completing sentences.\n",
    "**ChatPromptTemplates** are specifically designed for tasks that involve engaging in conversations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "453ecb45-ad4e-4cb6-aed5-e69f9085b722",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -r ./requirements.txt -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aceb9a44-570c-4528-95e0-cb9e0cbd68b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load the environment variables.\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "load_dotenv(find_dotenv(), override=True)   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a101e69-14db-4acc-a8ad-6c5eca6358e9",
   "metadata": {},
   "source": [
    "# PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9b448185-b818-4fff-93bb-bff681e8bba4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' You are an experienced virologist.\\nWrite a few sentences about the following virus covid in hindi.'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# 3 single quotes enclosed string is similar to F-string. f-strings are string literals with an f before the opening quotation mark. They can include Python expressions enclosed in curly braces. Python will replace those expressions with their resulting values. So, this behavior turns f-strings into a string interpolation tool.\n",
    "# curly braces are used for the dynamic part of the template.\n",
    "\n",
    "template = ''' You are an experienced virologist.\n",
    "Write a few sentences about the following virus {virus} in {language}.'''\n",
    "\n",
    "prompt_template = PromptTemplate.from_template(template=template)\n",
    "\n",
    "prompt = prompt_template.format(virus='covid', language='hindi')\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d4faee69-61e2-4654-8d10-8fef00aac1d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "कोविड-19 वायरस एक नए प्रकार का कोरोना वायरस है जो मनुष्यों में संक्रमण फैलाता है। यह वायरस खांसी, बुखार, सांस लेने में कठिनाई और शरीर में दर्द का कारण बनता है। इसका पता लगाने और इसका इलाज करने के लिए वैज्ञानिकों ने कई उपाय और वैक्सीन विकसित की है।\n"
     ]
    }
   ],
   "source": [
    "llm = ChatOpenAI(model_name='gpt-3.5-turbo', temperature=0)\n",
    "output=llm.invoke(prompt)\n",
    "print(output.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96ca0bf1-15ce-45f9-b230-901a4a13cfc1",
   "metadata": {},
   "source": [
    "# ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "837d97da-c3e3-4834-a121-5105845f9054",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SystemMessage(content='You respond only in the JSON format.'), HumanMessage(content='Top 10 countries in Europe by population.')]\n"
     ]
    }
   ],
   "source": [
    "#HumanMessagePromptTemplate is used to create dynamic prompts from the user's text\n",
    "#SystemMessage is used to format the system message.\n",
    "#There is also a class called \"SystemMessagePromptTemplate\"(not used in this program) if you want to generate dynamic system messages.\n",
    "\n",
    "from langchain.prompts import ChatPromptTemplate, HumanMessagePromptTemplate\n",
    "from langchain_core.messages import SystemMessage\n",
    "\n",
    "chat_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        SystemMessage(content='You respond only in the JSON format.'),\n",
    "        HumanMessagePromptTemplate.from_template('Top {n} countries in {area} by population.')\n",
    "    ]\n",
    ")\n",
    "\n",
    "messages = chat_template.format_messages(n='10', area='Europe')\n",
    "print(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a5d6e5ac-9760-4cfd-b607-88fa1509919b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"1\": {\n",
      "        \"country\": \"Germany\",\n",
      "        \"population\": 83240525\n",
      "    },\n",
      "    \"2\": {\n",
      "        \"country\": \"United Kingdom\",\n",
      "        \"population\": 67886011\n",
      "    },\n",
      "    \"3\": {\n",
      "        \"country\": \"France\",\n",
      "        \"population\": 65273511\n",
      "    },\n",
      "    \"4\": {\n",
      "        \"country\": \"Italy\",\n",
      "        \"population\": 60461826\n",
      "    },\n",
      "    \"5\": {\n",
      "        \"country\": \"Spain\",\n",
      "        \"population\": 46754778\n",
      "    },\n",
      "    \"6\": {\n",
      "        \"country\": \"Ukraine\",\n",
      "        \"population\": 43733762\n",
      "    },\n",
      "    \"7\": {\n",
      "        \"country\": \"Poland\",\n",
      "        \"population\": 37887768\n",
      "    },\n",
      "    \"8\": {\n",
      "        \"country\": \"Romania\",\n",
      "        \"population\": 19237691\n",
      "    },\n",
      "    \"9\": {\n",
      "        \"country\": \"Netherlands\",\n",
      "        \"population\": 17134872\n",
      "    },\n",
      "    \"10\": {\n",
      "        \"country\": \"Belgium\",\n",
      "        \"population\": 11589623\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "llm = ChatOpenAI()\n",
    "output = llm.invoke(messages)\n",
    "print(output.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09be8943-da17-43f2-8928-7578e5c785cd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
