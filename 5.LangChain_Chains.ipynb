{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "041f0670-d167-48e8-a512-9ae9d7ad8fe6",
   "metadata": {},
   "source": [
    "LLMs can be used for a variety of tasks, but they are often limited in what they can do on their own. For simple tasks or applications, we can use LLMs in isolation. But for more complex tasks, it is often necessary to chain or combine different components. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b84a2285-d0e3-4b56-b4d6-e37f2f918372",
   "metadata": {},
   "source": [
    "**Chains** in LangChain are a series of steps and actions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87ec93d9-1aef-466e-90c6-5e1d2f3b5471",
   "metadata": {},
   "source": [
    "**Chains** allows us to combine multiple components together to solve a specific task and build an entire LLM application."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5581d58-4525-4579-8fa2-4d99bd8efa7b",
   "metadata": {},
   "source": [
    "LangChain provides a standard interface for chains, as well as some common implementations of chains to make it easy to create and use chains."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "664a6baa-5737-4fa6-83d0-872ec6381fcd",
   "metadata": {},
   "source": [
    "There are:\n",
    "1)Simple Chains\n",
    "2)Sequential Chains\n",
    "3)Custom Chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "43048c23-e2c1-4579-90a9-48b23c7bafff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -r ./requirements.txt -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1f528258-7c4c-4728-989d-1befb05bbc01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load the environment variables.\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "load_dotenv(find_dotenv(), override=True)   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a201c0d-77b0-4b93-a736-4bd4982b4a58",
   "metadata": {},
   "source": [
    "# 1)Simple Chains\n",
    "It consists of a single LLM that is used to perform a single task. Simple chains are easy to create and use and also relatively efficient. However, they are limited in what they can do. \n",
    "for more complex tasks, it is often necessary to use sequential chains."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a4bccd86-c0b0-4036-aa98-e4905f5722d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m You are an experienced virologist.\n",
      "Write a few sentences about the following virus covid in english.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "{'virus': 'covid', 'language': 'english', 'text': 'COVID-19, also known as the coronavirus, is a highly contagious virus that primarily spreads through respiratory droplets. It belongs to the family of coronaviruses and has caused a global pandemic since its emergence in late 2019. The virus has led to widespread illness, hospitalizations, and deaths, prompting governments and health organizations to implement strict measures to control its spread. Research and vaccination efforts are ongoing to combat the virus and protect public health.'}\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "llm = ChatOpenAI()\n",
    "template = ''' You are an experienced virologist.\n",
    "Write a few sentences about the following virus {virus} in {language}.'''\n",
    "\n",
    "prompt_template = PromptTemplate.from_template(template=template)\n",
    "\n",
    "\n",
    "#Create the chain by calling LLMChain() constructor.This constructor sets up a simple chain and takes the prompt template, fills it with user input and returns the response from the LLM.\n",
    "\n",
    "chain = LLMChain(\n",
    "    llm=llm,\n",
    "    prompt = prompt_template, \n",
    "    #If you like to run the chain in verbose mode to display intermediate logs, then add \"verbose=True\" to the chain constructor \n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "output= chain.invoke({'virus':'covid', 'language': 'english'})\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee7e813a-e773-4f15-8d59-4d5b9bbe94cd",
   "metadata": {},
   "source": [
    "**Note**:-In the above example, the prompt template requires two variables, but if it requires only one variable then we can call \"chain.invoke()\" with a string variable as an argument instead of a dict. For detail see below example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "184feeba-0c43-4d1e-abfa-e0db4fde70ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter Country:  canada\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mWhat is the capital of canada? List the top 3 places to visit in that city. Use bullet points.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "The capital of Canada is Ottawa.\n",
      "\n",
      "Top 3 places to visit in Ottawa:\n",
      "\n",
      "- Parliament Hill\n",
      "- National Gallery of Canada\n",
      "- ByWard Market\n"
     ]
    }
   ],
   "source": [
    "template = 'What is the capital of {country}? List the top 3 places to visit in that city. Use bullet points.'\n",
    "prompt_template = PromptTemplate.from_template(template=template)\n",
    "\n",
    "chain = LLMChain(\n",
    "    llm=llm,\n",
    "    prompt = prompt_template, \n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "country = input('Enter Country: ')\n",
    "output = chain.invoke(country)\n",
    "#Here \"output\" is a dictionary and \"text\" is a key of the dictionary. The value of the text key contains the response.\n",
    "print(output['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74e1825b-b5a2-4356-a4f2-702cc8866d3d",
   "metadata": {},
   "source": [
    "# 2)Sequential Chains\n",
    "With **Sequential chains**, you can make a series of calls to one or more LLMs. You can take the output from one chain and use it as the input to another chain. \n",
    "\n",
    "There are two types of sequential chains:\n",
    "**1)SimpleSequentialChain\n",
    "2)General form of sequential chains**\n",
    "\n",
    "**SimpleSequentialChain** represents a series of chains, where each individual chain has a single input and a single output, and the output of one step is used as input to the next.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9610dc9b-bc37-4132-8157-3c8ade116453",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SimpleSequentialChain chain...\u001b[0m\n",
      "\u001b[36;1m\u001b[1;3mSure, here is an example of a simple API implemented using Node.js:\n",
      "\n",
      "```javascript\n",
      "// Import required modules\n",
      "const express = require('express');\n",
      "\n",
      "// Create an instance of Express\n",
      "const app = express();\n",
      "const PORT = 3000;\n",
      "\n",
      "// Define a sample data object\n",
      "const data = {\n",
      "  name: 'John Doe',\n",
      "  age: 30,\n",
      "  occupation: 'Scientist'\n",
      "};\n",
      "\n",
      "// Define a route to retrieve the sample data\n",
      "app.get('/data', (req, res) => {\n",
      "  res.json(data);\n",
      "});\n",
      "\n",
      "// Start the server\n",
      "app.listen(PORT, () => {\n",
      "  console.log(`Server is running on http://localhost:${PORT}`);\n",
      "});\n",
      "```\n",
      "\n",
      "In this code snippet, we are creating a simple API using Express, a popular Node.js framework for building web applications. We define a route `/data` that returns a JSON response containing sample data. When the server is started, it listens on port 3000 and outputs a message to the console.\n",
      "\n",
      "To run this code, save it in a file (e.g., `api.js`) and run `node api.js` in the terminal. You can then access the API at `http://localhost:3000/data` to retrieve the sample data.\u001b[0m\n",
      "\u001b[33;1m\u001b[1;3mThis code snippet creates a basic Express application in Node.js. \n",
      "\n",
      "First, the code imports the required `express` module, which is used to create the API. \n",
      "\n",
      "Next, an instance of the Express application is created, and the port number (3000) is defined. \n",
      "\n",
      "A sample data object named `data` is defined with three key-value pairs - `name`, `age`, and `occupation`. \n",
      "\n",
      "A route is defined using `app.get('/data', (req, res) => { ... })`, where `req` represents the request object and `res` represents the response object. When a `GET` request is made to the `/data` endpoint, the API will respond with the sample data in JSON format using `res.json(data)`.\n",
      "\n",
      "Finally, the server is started by calling `app.listen(PORT, () => { ... })`, and a message is logged to the console to indicate that the server is running.\n",
      "\n",
      "To run this API, save the code in a file (e.g., `api.js`) and run it using the Node.js runtime environment by executing `node api.js` in the terminal. Once the server starts running, you can access the API endpoint at `http://localhost:3000/data` to retrieve the sample data object in JSON format.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "This code snippet creates a basic Express application in Node.js. \n",
      "\n",
      "First, the code imports the required `express` module, which is used to create the API. \n",
      "\n",
      "Next, an instance of the Express application is created, and the port number (3000) is defined. \n",
      "\n",
      "A sample data object named `data` is defined with three key-value pairs - `name`, `age`, and `occupation`. \n",
      "\n",
      "A route is defined using `app.get('/data', (req, res) => { ... })`, where `req` represents the request object and `res` represents the response object. When a `GET` request is made to the `/data` endpoint, the API will respond with the sample data in JSON format using `res.json(data)`.\n",
      "\n",
      "Finally, the server is started by calling `app.listen(PORT, () => { ... })`, and a message is logged to the console to indicate that the server is running.\n",
      "\n",
      "To run this API, save the code in a file (e.g., `api.js`) and run it using the Node.js runtime environment by executing `node api.js` in the terminal. Once the server starts running, you can access the API endpoint at `http://localhost:3000/data` to retrieve the sample data object in JSON format.\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain import PromptTemplate\n",
    "from langchain.chains import LLMChain, SimpleSequentialChain\n",
    "\n",
    "llm1 = ChatOpenAI(model_name='gpt-3.5-turbo', temperature=0.5)\n",
    "prompt_template1 = PromptTemplate.from_template(\n",
    "    template='You are an experienced scientist and Node programmer. Write a code that implements the concept of {concept}.'\n",
    ")\n",
    "chain1 = LLMChain(llm=llm1, prompt=prompt_template1)\n",
    "\n",
    "\n",
    "llm2 = ChatOpenAI(model_name='gpt-3.5-turbo', temperature=1.2)\n",
    "#llm2 = ChatOpenAI(model_name='gpt-4-turbo-preview', temperature=1.2)\n",
    "prompt_template2 = PromptTemplate.from_template(\n",
    "    template='Given the node code {code}, describe it as detailed as possible.'\n",
    ")\n",
    "chain2 = LLMChain(llm=llm2, prompt=prompt_template2)\n",
    "\n",
    "\n",
    "overall_chain = SimpleSequentialChain(chains=[chain1, chain2], verbose=True)\n",
    "\n",
    "output = overall_chain.invoke('API')\n",
    "\n",
    "print(output['output'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "307aad78-f4ba-4d32-932c-239fd25f9fce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
