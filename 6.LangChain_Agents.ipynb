{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6391c2c3-234a-4182-a6e1-d02d9be997ed",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "**LLMs are incredibly powerful, but they lack the ability to perform certain tasks that even the simplest application can do easily. For example, LLMs struggle with logic, calculation, or communicating with other external components.**\n",
    "\n",
    "**Example1**: If I ask GPT4, \"What is the answer to (5.1 to the power of 7.3) 5.1**7.3?\" then GPT4 fails to answer it correctly. Calculating powers where the exponent is not a whole number, is a complex operation and can't be done by an AI model. Any calculator or core Python code can do this operation easily. This is because GPT4 uses an approximation while Python uses the exact mathematical formula.\n",
    "\n",
    "**In conclusion, LLMs are powerful tools, but they are not perfect. They can be used to generate text, translate languages, and answer questions, but they cannot replace calculators or other tools that are designed for specific tasks.**\n",
    "\n",
    "**Example2**If we give ChatGPT the task of writing an article about LangChain Agents. **Then it hallucinates(Which means it gives some output article but nothing is true in this article.). It completely made up the answer. That's because it was trained on data available till late 2021. So to solve this problem, there are plugins and Agents. Plugins help GPT4 browse the internet and access updated information. Plugins are external tools that are similar to agents. Here we are discussing LangChain Agents.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0a7590c-8953-46c9-93e3-f3c7d60ceb0c",
   "metadata": {},
   "source": [
    "# Agents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c41a61c3-6e8b-427a-95b8-9a55916aba33",
   "metadata": {},
   "source": [
    "**Agents are enabling tools for LLMs. Using Agents LLMs can run code, do calculations, search the web, or run SQL queries.** \n",
    "Agents make LangChain very useful. Agents combine LangChain tools and chains."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7197ddbb-25ba-4bc4-ae69-08526b3183bd",
   "metadata": {},
   "source": [
    "## Python REPL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8344c04-58d0-45a2-95af-fd70c833cc3a",
   "metadata": {},
   "source": [
    "We've seen that LLMs lack the ability to solve complex calculations, so we are going to take another approach. Instead of having the LLMs generate the answer directly, which is difficult, we will instruct the LLMs to generate the Python code to calculate the answer, and then run that code in a Python interpreter to get the answer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b775dc73-eaba-414e-81ba-66a668a1718c",
   "metadata": {},
   "source": [
    "Note:  Here we are installing a package called LangChain_experimental.It contains experimental components and features related to LangChain. It's important to note that this library is intended for research and exploration, and some parts are not yet stable or secure for production use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "79eb9db5-498f-45a6-8c6b-c090c5d25c35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -q langchain_experimental"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cc7f182f-3d31-4eb7-b99f-638d958cea0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -r ./requirements.txt -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "21b91506-7d8e-4306-a34e-f31d2b48af7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "load_dotenv(find_dotenv(), override=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbdc7e9e-1138-46f4-86f3-07eb7946672f",
   "metadata": {},
   "source": [
    "note: In the following example, there is no LLM involved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e245af21-0a3e-4c28-a303-7eb7a0abf889",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Python REPL can execute arbitrary code. Use with caution.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'[13, 26, 39, 52, 65, 78, 91]\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_experimental.utilities import PythonREPL\n",
    "\n",
    "# The following instance of the PythonREPL class provides a way to execute Python code or Python expression within the REPL environment.\n",
    "python_repl = PythonREPL()\n",
    "python_repl.run('print([n for n in range(1, 100) if n % 13 == 0])')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7460e5a-f9cb-4bfc-990e-1a8f90a15906",
   "metadata": {},
   "source": [
    "## Creating an Agent."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cd337e2-13cb-4275-a09d-1f39fbee2fef",
   "metadata": {},
   "source": [
    " In the following code, we are creating an agent.(not giving correct outputt everytime)\n",
    " \n",
    " 1)For this, we are importing a function called **create_python_agent** from the **langchain_experimental.agents.agent_toolkits**. **create_python_agent** function is used to create a special type of LangChain Agent, that can interact with Python code. \n",
    " \n",
    " 2)Next, we import the **PythonREPLTool** class. This tool provides a Python REPL environment within LangChain allowing the agent to execute Python code directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "47987aac-0994-47a3-8eee-98c9464c49ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mWe can first calculate the factorial of 12 and then find the square root of that result. Finally, we can display the square root with 4 decimal points.\n",
      "Action: Python_REPL\n",
      "Action Input: import math\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mWe need to import the math module to access the square root function.\n",
      "Action: Python_REPL\n",
      "Action Input: math.factorial(12)\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mWe have calculated the factorial of 12, now we can find the square root of this result.\n",
      "Action: Python_REPL\n",
      "Action Input: math.sqrt(math.factorial(12))\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mWe have found the square root of the factorial of 12, now we can display it with 4 decimal points.\n",
      "Action: Python_REPL\n",
      "Action Input: \"{:.4f}\".format(math.sqrt(math.factorial(12)))\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mSyntaxError('invalid decimal literal', ('<string>', 1, 4, '{:.4f}\".format(math.sqrt(math.factorial(12)))', 1, 4))\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mThere seems to be a syntax error in the format string. Let's correct it.\n",
      "Action: Python_REPL\n",
      "Action Input: \"{:.4f}\".format(math.sqrt(math.factorial(12)))\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mSyntaxError('invalid decimal literal', ('<string>', 1, 4, '{:.4f}\".format(math.sqrt(math.factorial(12)))', 1, 4))\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mThere seems to be an issue with the format string. Let's correct it by using the print function to display the result with 4 decimal points.\n",
      "Action: Python_REPL\n",
      "Action Input: print(\"{:.4f}\".format(math.sqrt(math.factorial(12))))\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m21886.1052\n",
      "\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI now know the final answer\n",
      "Final Answer: 21886.1052\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'Calculate the square root of the factorial of 12 and display it with 4 decimal points',\n",
       " 'output': '21886.1052'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_experimental.agents.agent_toolkits import create_python_agent\n",
    "from langchain_experimental.tools.python.tool import PythonREPLTool\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model='gpt-3.5-turbo', temperature=0)\n",
    "\n",
    "# instantiating a Python agent executor using the OpenAI LLM. This allows us to have the language model execute Python code.\n",
    "agent_executor = create_python_agent(\n",
    "    llm=llm,\n",
    "    tool= PythonREPLTool(), # Tools are essentially functions that agents can use to interact with the outside world. These can range from general utilities, such as a math calculator or a search function, to other chains or even other agents. \n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# Executing the Python Agent\n",
    "agent_executor.invoke('Calculate the square root of the factorial of 12 and display it with 4 decimal points')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8a01bd02-c328-4e90-bf17-e799f6f2af94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mWe can calculate the result of 5.1 raised to the power of 7.3 using Python.\n",
      "Action: Python_REPL\n",
      "Action Input: print(5.1 ** 7.3)\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m146306.05007233328\n",
      "\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mThe result of 5.1 raised to the power of 7.3 is 146306.05007233328.\n",
      "Final Answer: 146306.05007233328\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "response = agent_executor.invoke('What is the answer to 5.1 ** 7.3?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b5af091c-ae53-42ab-bcc3-cfadc69c54f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': 'What is the answer to 5.1 ** 7.3?', 'output': '146306.05007233328'}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b789035f-59cf-413d-9ec4-628060dd9e2f",
   "metadata": {},
   "source": [
    "response is a Python dictionary with **two key-value pairs**.\n",
    "1)input(what the user asked) 2)output(contains LLM response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "223f26a6-fa73-4411-a8a7-2cc08f99a6c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is the answer to 5.1 ** 7.3?\n"
     ]
    }
   ],
   "source": [
    "print(response['input'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "122d0ea5-6cb9-4e8b-951c-6eea9a8d456b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "146306.05007233328\n"
     ]
    }
   ],
   "source": [
    "print(response['output'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
